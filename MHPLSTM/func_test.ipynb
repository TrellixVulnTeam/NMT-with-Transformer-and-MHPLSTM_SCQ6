{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [0, 3, 4],\n",
      "        [1, 0, 3]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[[ True,  True,  True]],\n",
      "\n",
      "        [[False,  True,  True]],\n",
      "\n",
      "        [[ True, False,  True]]])\n",
      "torch.Size([3, 1, 3])\n",
      "tensor([[[ True, False, False],\n",
      "         [ True,  True, False],\n",
      "         [ True,  True,  True]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "\n",
    "def get_pad_mask(seq, pad_idx):\n",
    "    return (seq != pad_idx).unsqueeze(-2)\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    \"\"\"For masking out the subsequent info.\"\"\"\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = (1 - torch.triu(\n",
    "        torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
    "    \n",
    "    return subsequent_mask\n",
    "\n",
    "X = torch.tensor([[1, 2, 3], [0, 3, 4], [1, 0, 3]])\n",
    "print(X)\n",
    "print(X.shape)\n",
    "Y = get_pad_mask(X, 0)\n",
    "print(Y)\n",
    "print(Y.shape)\n",
    "Z = get_subsequent_mask(X)\n",
    "print(Z)\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  torch.Size([16, 256, 128])\n",
      "X_steps size: 256\n",
      "X_steps[0[.shape:  torch.Size([16, 128])\n",
      "X_steps[0]:  tensor([[0.7357, 0.8787, 0.5362,  ..., 0.9408, 0.4598, 0.4150],\n",
      "        [0.0955, 0.8765, 0.0617,  ..., 0.7000, 0.6588, 0.8330],\n",
      "        [0.7069, 0.3405, 0.1005,  ..., 0.5733, 0.8304, 0.2003],\n",
      "        ...,\n",
      "        [0.3625, 0.0768, 0.6233,  ..., 0.0704, 0.6336, 0.4173],\n",
      "        [0.0625, 0.3860, 0.9970,  ..., 0.3127, 0.6703, 0.9729],\n",
      "        [0.4361, 0.4837, 0.7813,  ..., 0.5262, 0.5615, 0.4900]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((16, 256, 128))\n",
    "print(\"X.shape: \", X.shape)\n",
    "# X = X.transpose(0, 1)\n",
    "X_steps = X.chunk(256, 1)\n",
    "X_steps = [sample.squeeze(1) for sample in X_steps]\n",
    "print(\"X_steps size:\", len(X_steps))\n",
    "print(\"X_steps[0[.shape: \", X_steps[0].shape)\n",
    "print(\"X_steps[0]: \", X_steps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_of_words_presentation:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [0., 2., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [0., 3., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [0., 4., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "vocabulary:\n",
      "{'game': 3, 'of': 6, 'thrones': 10, 'is': 5, 'an': 1, 'amazing': 0, 'tv': 11, 'series': 7, 'the': 9, 'best': 2, 'so': 8, 'great': 4}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from BagOfWords import *\n",
    "vectorizer, vocab, vocab_size = build_vectorizer_and_vocab([\n",
    "    'Game of Thrones is an amazing tv series!',\n",
    "    'Game of Thrones is the best tv series!',\n",
    "    'Game of Thrones is so great'])\n",
    "\n",
    "print(\"bag_of_words_presentation:\")\n",
    "print(bag_of_words_presentation('Game of Thrones is an great tv series! an an an', vectorizer, vocab_size))\n",
    "print(\"vocabulary:\")\n",
    "print(vocab)\n",
    "print(vocab['thrones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cceba70ee793f7bf18f36682d928c8f947b789467867bbf028c4d87177e69b0a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
